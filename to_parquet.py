# import pandas as pd
# import re
# from pathlib import Path
# import pyarrow
#
#
# def extract_number(value: str) -> float | None:
#     """
#     –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ (–∏–ª–∏ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –¥–∏–∞–ø–∞–∑–æ–Ω–∞) –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è.
#     –ü—Ä–∏–º–µ—Ä—ã:
#         '108.5 - 109¬∞C' ‚Üí 108.75
#         '> 615¬∞C'       ‚Üí 615
#         '1040 K(767 ¬∞C)'‚Üí 1040
#         '-153.7¬∞C'      ‚Üí -153.7
#     """
#     if pd.isna(value):
#         return None
#
#     s = str(value)
#
#     # –ù–∞–π–¥—ë–º –≤—Å–µ —á–∏—Å–ª–∞ (–≤–∫–ª—é—á–∞—è –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –¥—Ä–æ–±–Ω—ã–µ)
#     numbers = re.findall(r"-?\d+(?:\.\d+)?", s)
#     if not numbers:
#         return None
#
#     # –ï—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ
#     if len(numbers) >= 2:
#         nums = [float(n) for n in numbers[:2]]
#         return sum(nums) / len(nums)
#
#     return float(numbers[0])
#
#
# def csv_from_drive_to_parquet(file_id: str, parquet_filename: str | None = None):
#     """
#     –ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Å Google Drive, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Parquet.
#     """
#     # --- 1Ô∏è‚É£ –§–æ—Ä–º–∏—Ä—É–µ–º URL –∏ —á–∏—Ç–∞–µ–º CSV ---
#     file_url = f"https://drive.google.com/uc?id={file_id}"
#     df = pd.read_csv(file_url)
#     print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏ {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ Google Drive")
#
#     # --- 2Ô∏è‚É£ –û—á–∏—Å—Ç–∏–º –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã ---
#     for col in ["melting_point", "boiling_point"]:
#         if col in df.columns:
#             before = df[col].notna().sum()
#             df[col] = df[col].apply(extract_number)
#             after = df[col].notna().sum()
#             print(f"üå° {col}: —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {after} –∏–∑ {before} –∑–Ω–∞—á–µ–Ω–∏–π")
#
#     # --- 3Ô∏è‚É£ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ---
#     numeric_cols = [
#         "id", "pubchem_id", "weight", "lethaldose", "min_risk_level",
#         "actor_id", "export", "moldb_average_mass", "moldb_mono_mass", "logp"
#     ]
#     for col in numeric_cols:
#         if col in df.columns:
#             df[col] = pd.to_numeric(df[col], errors="coerce")
#
#     # --- 4Ô∏è‚É£ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã ---
#     datetime_cols = ["created_at", "updated_at"]
#     for col in datetime_cols:
#         if col in df.columns:
#             df[col] = pd.to_datetime(df[col], errors="coerce")
#
#     # --- 5Ô∏è‚É£ –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ---
#     string_cols = [c for c in df.columns if c not in numeric_cols + datetime_cols + ["melting_point", "boiling_point"]]
#     df[string_cols] = df[string_cols].astype("string")
#
#     print("üìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã")
#
#     # --- 6Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ---
#     if parquet_filename is None:
#         parquet_filename = Path("converted_data_fixed.parquet")
#     else:
#         parquet_filename = Path(parquet_filename)
#
#     df.to_parquet(parquet_filename, index=False)
#     print(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫: {parquet_filename.resolve()}")
#
#     return df
#
#
# # --- –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ---
# if __name__ == "__main__":
#     df = csv_from_drive_to_parquet("1i_H46ci0vi-B17v8UKIGfpQeGRpaa2uI")

import pandas as pd
import re
from pathlib import Path
import pyarrow


def extract_number(value: str) -> float | None:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ (–∏–ª–∏ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –¥–∏–∞–ø–∞–∑–æ–Ω–∞) –∏–∑ —Å—Ç—Ä–æ–∫–∏ —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è.
    –ü—Ä–∏–º–µ—Ä—ã:
        '108.5 - 109¬∞C' ‚Üí 108.75
        '> 615¬∞C'       ‚Üí 615
        '1040 K(767 ¬∞C)'‚Üí 1040
        '-153.7¬∞C'      ‚Üí -153.7
    """
    if pd.isna(value):
        return None

    s = str(value)
    numbers = re.findall(r"-?\d+(?:\.\d+)?", s)
    if not numbers:
        return None

    # –ï—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî –±–µ—Ä—ë–º —Å—Ä–µ–¥–Ω–µ–µ
    if len(numbers) >= 2:
        nums = [float(n) for n in numbers[:2]]
        return sum(nums) / len(nums)

    return float(numbers[0])


def clean_route(value):
    """
    –û—á–∏—â–∞–µ—Ç –∫–æ–ª–æ–Ω–∫—É route_of_exposure –æ—Ç –∫–æ–¥–æ–≤ (–≤ —Å–∫–æ–±–∫–∞—Ö) –∏ –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤.
    –ü—Ä–∏–º–µ—Ä:
        'Oral (L4); inhalation (L4); dermal (L4)' ‚Üí 'oral, inhalation, dermal'
    """
    if pd.isna(value):
        return None
    cleaned = re.sub(r"\(.*?\)", "", value)        # —É–±–∏—Ä–∞–µ–º –≤—Å—ë –≤ —Å–∫–æ–±–∫–∞—Ö
    cleaned = re.sub(r"[\.;]", ",", cleaned)       # –∑–∞–º–µ–Ω—è–µ–º ; –∏ . –Ω–∞ –∑–∞–ø—è—Ç—ã–µ
    cleaned = re.sub(r"\s+", " ", cleaned).strip() # —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    return cleaned.lower()


def normalize_carcinogenicity(value):
    """
    –ü—Ä–∏–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è carcinogenicity –∫ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:
    - 'carcinogenic' (–≤–∫–ª—é—á–∞–µ—Ç IARC 1, Group 1 –∏ —Ç.–ø.)
    - 'possible/uncertain' (–≤–∫–ª—é—á–∞–µ—Ç 2A, 2B, possible, probable)
    - 'non-carcinogenic' (–≤–∫–ª—é—á–∞–µ—Ç not classifiable, no evidence)
    """
    if pd.isna(value):
        return None

    s = str(value).lower().strip()

    # --- –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: —è–≤–Ω–æ –∫–∞–Ω—Ü–µ—Ä–æ–≥–µ–Ω–Ω—ã–µ ---
    if re.search(r"\b(1[, ]|group 1|carcinogenic to humans)\b", s):
        return "carcinogenic"

    # --- –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –≤–æ–∑–º–æ–∂–Ω–æ/–≤–µ—Ä–æ—è—Ç–Ω–æ –∫–∞–Ω—Ü–µ—Ä–æ–≥–µ–Ω–Ω—ã–µ ---
    if re.search(r"\b(2a|2b|possible|probable|suspected)\b", s):
        return "uncertain"

    # --- –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –Ω–µ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç—Å—è / –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö ---
    if re.search(r"\b(3|not classifiable|no indication|non|not carcinogenic)\b", s):
        return "non-carcinogenic"

    # --- –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
    return "uncertain"


def csv_from_drive_to_parquet(file_id: str, parquet_filename: str | None = None):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç CSV —Å Google Drive, –æ—á–∏—â–∞–µ—Ç –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ Parquet.
    """
    # --- 1Ô∏è‚É£ –ó–∞–≥—Ä—É–∂–∞–µ–º CSV ---
    file_url = f"https://drive.google.com/uc?id={file_id}"
    df = pd.read_csv(file_url)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –∏ {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ Google Drive")

    # --- 2Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä ---
    for col in ["melting_point", "boiling_point"]:
        if col in df.columns:
            before = df[col].notna().sum()
            df[col] = df[col].apply(extract_number)
            after = df[col].notna().sum()
            print(f"üå° {col}: —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–æ {after} –∏–∑ {before} –∑–Ω–∞—á–µ–Ω–∏–π")

    # --- 3Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ –ø—É—Ç–∏ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è —Ç–æ–∫—Å–∏–Ω–æ–≤ ---
    if "route_of_exposure" in df.columns:
        df["route_of_exposure"] = df["route_of_exposure"].apply(clean_route)
        print("üß™ –ö–æ–ª–æ–Ω–∫–∞ 'route_of_exposure' —É—Å–ø–µ—à–Ω–æ –æ—á–∏—â–µ–Ω–∞ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω–∞)")

    # --- 4Ô∏è‚É£ –û—á–∏—Å—Ç–∫–∞ –æ–Ω–∫–æ–≥–µ–Ω–Ω–æ—Å—Ç–∏ ---
    if "carcinogenicity" in df.columns:
        df["carcinogenicity"] = df["carcinogenicity"].apply(normalize_carcinogenicity)
        print("‚ò£Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'carcinogenicity' –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –¥–æ —Ç—Ä—ë—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

    # --- 5Ô∏è‚É£ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ ---
    numeric_cols = [
        "id", "pubchem_id", "weight", "lethaldose", "min_risk_level",
        "actor_id", "export", "moldb_average_mass", "moldb_mono_mass", "logp"
    ]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # --- 6Ô∏è‚É£ –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—ã ---
    datetime_cols = ["created_at", "updated_at"]
    for col in datetime_cols:
        if col in df.columns:
            df[col] = pd.to_datetime(df[col], errors="coerce")

    # --- 7Ô∏è‚É£ –û—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî —Å—Ç—Ä–æ–∫–∏ ---
    string_cols = [
        c for c in df.columns
        if c not in numeric_cols + datetime_cols + ["melting_point", "boiling_point"]
    ]
    df[string_cols] = df[string_cols].astype("string")

    print("üìä –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –∏ –æ—á–∏—â–µ–Ω—ã")

    # --- 8Ô∏è‚É£ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ---
    if parquet_filename is None:
        parquet_filename = Path("converted_data_fixed.parquet")
    else:
        parquet_filename = Path(parquet_filename)

    df.to_parquet(parquet_filename, index=False)
    print(f"üíæ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –∫–∞–∫: {parquet_filename.resolve()}")

    return df


# --- –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è ---
if __name__ == "__main__":
    df = csv_from_drive_to_parquet("1i_H46ci0vi-B17v8UKIGfpQeGRpaa2uI")

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
df["route_of_exposure"].head(10)
